{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "# import snntorch as surrogate\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import utils\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_grad = surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN_FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2,12,5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.lif1 = snn.Leaky(beta = beta, spike_grad = spike_grad, init_hidden = True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(12,32,5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.lif2 = snn.Leaky(beta = beta, spike_grad = spike_grad, init_hidden = True)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32*5*5, 10)\n",
    "        self.lif_out = snn.Leaky(beta = beta, spike_grad = spike_grad, init_hidden = True, output = True)\n",
    "\n",
    "    def forward(self, x_seq):\n",
    "        # x_seq has shape (t, Batch_size, Polarity, x, y)\n",
    "        \n",
    "        spk_rec = []\n",
    "\n",
    "        # temporal loop inthe forward pass\n",
    "        for step in range(x_seq.size[0]):\n",
    "            x_step = x_seq[step]\n",
    "\n",
    "            cur1 = self.pool1(self.conv1(x_step))\n",
    "            spk1 = self.lif1(cur1)\n",
    "\n",
    "            cur2 = self.pool2(self.conv2(spk1))\n",
    "            spk2 = self.lif2(cur2)\n",
    "\n",
    "            flat = self.flatten(spk2)\n",
    "            cur_out = self.fc1(flat)\n",
    "\n",
    "            spk_out, mem_out = self.lif_out(cur_out)\n",
    "\n",
    "            spk_rec.append(spk_out)\n",
    "\n",
    "        return torch.stack(spk_rec, dim = 0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2,12,5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.lif1 = snn.Leaky(beta = beta, spike_grad = spike_grad)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(12,32,5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.lif2 = snn.Leaky(beta = beta, spike_grad = spike_grad, init_hidden = True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
